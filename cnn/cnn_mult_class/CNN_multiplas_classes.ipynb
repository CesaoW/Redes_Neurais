{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76ca7df",
   "metadata": {},
   "source": [
    "### Redes Neurais Artificiais\n",
    "### Professor Ciniro Nametala - IFMG\n",
    "\n",
    "## Classificação de expressões faciais com Redes Neurais Convolucionais (CNN)\n",
    "\n",
    "Neste trabalho vamos construir um classificador de expressões faciais utilizando Redes Neurais Convolucionais (CNN). O projeto é dividido em três etapas principais:\n",
    "\n",
    "1. **Captura de imagens**: Utilizando a webcam, o aluno captura imagens de seu rosto em três expressões (feliz, triste e furioso)\n",
    "2. **Treinamento da CNN**: Uma rede neural convolucional é treinada para reconhecer as três expressões\n",
    "3. **Predição ao vivo**: O modelo treinado é utilizado para classificar as expressões do rosto em tempo real através da webcam\n",
    "\n",
    "As imagens são capturadas em escala de cinza com resolução configurável de nxn pixels. O modelo utiliza camadas convolucionais para extrair características das imagens e camadas densas para classificação.\n",
    "\n",
    "**Classes do modelo:**\n",
    "- FELIZ (0)\n",
    "- TRISTE (1)\n",
    "- FURIOSO (2)\n",
    "- NEUTRO (quando confiança < 60%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31713402",
   "metadata": {},
   "source": [
    "## 1. Preparação do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47771a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao para deixar o jupyter com celulas preenchendo toda a tela\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria as pastas para armazenar o dataset e os modelos treinados\n",
    "import os\n",
    "os.makedirs(\"dataset\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82fc0a",
   "metadata": {},
   "source": [
    "### 1.1 Importação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#para exportar o requeriments\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "#bibliotecas para trabalhar com dados e graficos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "#bibliotecas do scikit-learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#biblioteca para exportacoes e importacoes de arquivos\n",
    "from joblib import dump, load\n",
    "\n",
    "#biblioteca para implementar uma barra de progresso\n",
    "import progressbar\n",
    "\n",
    "#biblioteca para tocar sons\n",
    "import pygame\n",
    "\n",
    "#bibliotecas para captura de imagens\n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "#bibliotecas para deep learning\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#bibliotecas para plotar graficos do keras\n",
    "import pydot as pyd\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "tensorflow.keras.utils.pydot = pyd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b72c9",
   "metadata": {},
   "source": [
    "### 1.2 Verificando versões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84cff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "import matplotlib\n",
    "print(f\"Matplotlib version: {matplotlib.__version__}\")\n",
    "\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff2e769",
   "metadata": {},
   "source": [
    "### 1.3 Checagem de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f87ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificacao de GPU\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"TensorFlow encontrou GPUs: {len(gpus) > 0}\")\n",
    "print(f\"Dispositivos GPU TensorFlow: {gpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ab7b2",
   "metadata": {},
   "source": [
    "## 2. Configurações do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#CONFIGURACOES DE CAPTURA\n",
    "#------------------------------\n",
    "\n",
    "#tempo de captura em segundos\n",
    "capture_time = 10\n",
    "\n",
    "#quantidade de fotos por classe\n",
    "capture_count = 50\n",
    "\n",
    "#resolucao das imagens (quadradas)\n",
    "img_size = 128\n",
    "\n",
    "#tamanho da area de captura na tela (em pixels)\n",
    "box_size = 400\n",
    "\n",
    "#realizar nova captura (True) ou usar capturas existentes (False)\n",
    "#se True, apaga o conteudo da pasta 'captura' e tira novas fotos\n",
    "#se False, usa as fotos existentes na pasta 'captura'\n",
    "new_capture = True\n",
    "\n",
    "#------------------------------\n",
    "#CONFIGURACOES DE TREINAMENTO\n",
    "#------------------------------\n",
    "\n",
    "#gerar um novo modelo ou usar um pronto\n",
    "new_model = True\n",
    "\n",
    "#realizar data augmentation (rotacao, zoom, flip)\n",
    "augmentation_exec = True\n",
    "\n",
    "#realizar normalizacao de dados (escala 0-1)\n",
    "normalization_exec = True\n",
    "\n",
    "#threshold de confianca para classificar como NEUTRO\n",
    "confidence_threshold = 0.60\n",
    "\n",
    "#nome do modelo\n",
    "model_name = 'cnn_expressoes_faciais'\n",
    "\n",
    "#classes do modelo\n",
    "class_names = ['FELIZ', 'TRISTE', 'FURIOSO']\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6852f",
   "metadata": {},
   "source": [
    "## 3. Captura de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca72797",
   "metadata": {},
   "source": [
    "### 3.1 Funções auxiliares de captura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58880f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_capture_folder(base_path='dataset'):\n",
    "    \"\"\"prepara a pasta de captura\"\"\"\n",
    "    folder_path = os.path.join(base_path, 'captura')\n",
    "\n",
    "    #se a pasta existe, apaga e recria\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f'pasta {folder_path} apagada')\n",
    "    \n",
    "    os.makedirs(folder_path)\n",
    "    print(f'pasta {folder_path} criada')\n",
    "    return folder_path\n",
    "\n",
    "def capture_images(class_name, num_images, capture_seconds, img_size, box_size, save_path):\n",
    "    \"\"\"captura imagens da webcam com countdown e preview\"\"\"\n",
    "    \n",
    "    #usa o backend AVFoundation no macOS para evitar crash\n",
    "    if sys.platform == 'darwin':\n",
    "        cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print('erro: nao foi possivel abrir a webcam')\n",
    "        return False\n",
    "\n",
    "    #calcula intervalo entre capturas\n",
    "    interval = capture_seconds / num_images\n",
    "\n",
    "    print(f'\\n=== capturando {class_name.upper()} ===')\n",
    "    print(f'posicione-se em {class_name.upper()} e pressione SPACE para iniciar...')\n",
    "    print('pressione Q para cancelar')\n",
    "    \n",
    "    window_name = 'Captura'\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    try:\n",
    "        #aguarda usuario pressionar space para iniciar\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            #espelha a imagem para facilitar posicionamento\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            #adiciona texto de instrucao\n",
    "            cv2.putText(frame, f'Posicione-se em {class_name.upper()}', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Pressione SPACE para iniciar', (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "            #desenha area de captura\n",
    "            h, w = frame.shape[:2]\n",
    "            cx, cy = w // 2, h // 2\n",
    "            cv2.rectangle(frame, (cx - box_size//2, cy - box_size//2),\n",
    "                        (cx + box_size//2, cy + box_size//2), (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(' '):\n",
    "                break\n",
    "            elif key == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyWindow(window_name)\n",
    "                cv2.waitKey(1)\n",
    "                return False\n",
    "\n",
    "        #inicia captura com countdown\n",
    "        start_time = time.time()\n",
    "        images_captured = 0\n",
    "        last_capture_time = 0\n",
    "\n",
    "        while images_captured < num_images:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            #espelha a imagem\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            remaining = max(0, capture_seconds - elapsed)\n",
    "\n",
    "            #desenha area de captura\n",
    "            h, w = frame.shape[:2]\n",
    "            cx, cy = w // 2, h // 2\n",
    "            cv2.rectangle(frame, (cx - box_size//2, cy - box_size//2),\n",
    "                        (cx + box_size//2, cy + box_size//2), (0, 0, 255), 2)\n",
    "\n",
    "            #adiciona countdown e contador de fotos\n",
    "            cv2.putText(frame, f'Tempo: {remaining:.1f}s', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f'Fotos: {images_captured}/{num_images}', (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f'{class_name.upper()}', (10, 90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.imshow(window_name, frame)\n",
    "\n",
    "            #captura imagem no intervalo correto\n",
    "            if elapsed - last_capture_time >= interval:\n",
    "                #extrai regiao de interesse (ROI)\n",
    "                roi = frame[cy - box_size//2:cy + box_size//2,\n",
    "                            cx - box_size//2:cx + box_size//2]\n",
    "\n",
    "                #converte para escala de cinza\n",
    "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                #redimensiona para tamanho desejado\n",
    "                roi_resized = cv2.resize(roi_gray, (img_size, img_size))\n",
    "\n",
    "                #salva imagem\n",
    "                filename = os.path.join(save_path, f'{class_name}_{images_captured + 1:03d}.jpg')\n",
    "                cv2.imwrite(filename, roi_resized)\n",
    "\n",
    "                images_captured += 1\n",
    "                last_capture_time = elapsed\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            if elapsed >= capture_seconds and images_captured >= num_images:\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        #libera a camera e fecha a janela de forma segura\n",
    "        cap.release()\n",
    "        cv2.destroyWindow(window_name)\n",
    "        #processa eventos pendentes\n",
    "        for _ in range(10):\n",
    "            cv2.waitKey(1)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    print(f'{images_captured} imagens de {class_name.upper()} capturadas')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7276baf",
   "metadata": {},
   "source": [
    "### 3.2 Execução da captura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9887823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#executa captura se new_capture=True\n",
    "if new_capture:\n",
    "    capture_path = prepare_capture_folder()\n",
    "    \n",
    "    print('\\n' + '='*50)\n",
    "    print('INICIANDO CAPTURA DE IMAGENS')\n",
    "    print('='*50)\n",
    "    print(f'tempo por classe: {capture_time} segundos')\n",
    "    print(f'fotos por classe: {capture_count}')\n",
    "    print(f'area de captura: {box_size}x{box_size} pixels')\n",
    "    print(f'resolucao final: {img_size}x{img_size} pixels (escala de cinza)')\n",
    "    print('='*50)\n",
    "    \n",
    "    #captura cada classe\n",
    "    for class_name in ['feliz', 'triste', 'furioso']:\n",
    "        success = capture_images(class_name, capture_count, capture_time, img_size, box_size, capture_path)\n",
    "        if not success:\n",
    "            print(f'captura de {class_name} cancelada')\n",
    "            break\n",
    "        time.sleep(1)  #pequena pausa entre capturas\n",
    "    \n",
    "    print('\\n' + '='*50)\n",
    "    print('CAPTURA FINALIZADA')\n",
    "    print('='*50)\n",
    "else:\n",
    "    capture_path = os.path.join('dataset', 'captura')\n",
    "    if os.path.exists(capture_path):\n",
    "        print(f'usando dataset existente: {capture_path}')\n",
    "    else:\n",
    "        print(f'erro: pasta {capture_path} nao encontrada')\n",
    "        print('defina new_capture=True para criar uma nova captura')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4129b",
   "metadata": {},
   "source": [
    "## 4. Análise de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac35b6",
   "metadata": {},
   "source": [
    "### 4.1 Carregamento das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb87b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path, class_names, img_size):\n",
    "    \"\"\"carrega imagens e retorna arrays de dados e rotulos\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, class_name in enumerate(class_names):\n",
    "        pattern = os.path.join(folder_path, f'{class_name.lower()}_*.jpg')\n",
    "        files = glob.glob(pattern)\n",
    "        \n",
    "        print(f'{class_name}: {len(files)} imagens encontradas')\n",
    "        \n",
    "        for file in files:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (img_size, img_size))\n",
    "                images.append(img)\n",
    "                labels.append(idx)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "#carrega as imagens\n",
    "capture_path = os.path.join('dataset', 'captura')\n",
    "x_data, y_data = load_images(capture_path, class_names, img_size)\n",
    "\n",
    "print(f'\\ntotal de imagens: {len(x_data)}')\n",
    "print(f'shape dos dados: {x_data.shape}')\n",
    "print(f'shape dos rotulos: {y_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf41d2b",
   "metadata": {},
   "source": [
    "### 4.2 Visualização das amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2996ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualiza algumas amostras de cada classe\n",
    "fig, axs = plt.subplots(3, 5, figsize=(12, 8))\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_indices = np.where(y_data == i)[0]\n",
    "    sample_indices = np.random.choice(class_indices, min(5, len(class_indices)), replace=False)\n",
    "    \n",
    "    for j, idx in enumerate(sample_indices):\n",
    "        axs[i, j].imshow(x_data[idx], cmap='gray')\n",
    "        axs[i, j].set_title(f'{class_name}')\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6239b",
   "metadata": {},
   "source": [
    "### 4.3 Sumarização estatística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sumarizacao",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumarizacao(x_data, y_data, class_names):\n",
    "    stats = []\n",
    "\n",
    "    for idx, class_name in enumerate(class_names):\n",
    "        class_data = x_data[y_data == idx]\n",
    "        \n",
    "        count = len(class_data)\n",
    "        mean_pixel = round(np.mean(class_data), 2)\n",
    "        std_pixel = round(np.std(class_data), 2)\n",
    "        min_pixel = round(np.min(class_data), 2)\n",
    "        max_pixel = round(np.max(class_data), 2)\n",
    "        \n",
    "        stats.append([class_name, count, mean_pixel, std_pixel, min_pixel, max_pixel])\n",
    "\n",
    "    headers = ['Classe', 'Quantidade', 'Média Pixel', 'Desvio Padrão', 'Mínimo', 'Máximo']\n",
    "\n",
    "    table = tabulate(stats, headers, tablefmt=\"pipe\")\n",
    "    print(table)\n",
    "\n",
    "sumarizacao(x_data, y_data, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distribuicao",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribuicao das classes\n",
    "unique, counts = np.unique(y_data, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar([class_names[i] for i in unique], counts, color=['blue', 'green', 'red'])\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.title('Distribuição das Classes')\n",
    "\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b5f66",
   "metadata": {},
   "source": [
    "### 4.4 Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adiciona dimensao do canal (escala de cinza = 1 canal)\n",
    "x_data = x_data.reshape(x_data.shape[0], img_size, img_size, 1)\n",
    "\n",
    "#normalizacao (escala 0-1)\n",
    "if normalization_exec:\n",
    "    x_data = x_data.astype('float32') / 255.0\n",
    "    print('dados normalizados para escala [0, 1]')\n",
    "\n",
    "#converte rotulos para one-hot encoding\n",
    "y_data_cat = to_categorical(y_data, num_classes)\n",
    "\n",
    "print(f'shape dos dados: {x_data.shape}')\n",
    "print(f'shape dos rotulos (one-hot): {y_data_cat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c745692",
   "metadata": {},
   "source": [
    "## 5. Separação dos conjuntos de dados (treino, validação e teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separa treino+validacao e teste\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(\n",
    "    x_data, y_data_cat, test_size=0.2, shuffle=True, random_state=42, stratify=y_data_cat\n",
    ")\n",
    "\n",
    "#separa treino e validacao\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train_val, y_train_val, test_size=0.25, shuffle=True, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f'x_train shape: {x_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'x_val shape: {x_val.shape}')\n",
    "print(f'y_val shape: {y_val.shape}')\n",
    "print(f'x_test shape: {x_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aug_section",
   "metadata": {},
   "source": [
    "### 5.1 Data Augmentation (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "augmentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configura data augmentation\n",
    "if augmentation_exec:\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    datagen.fit(x_train)\n",
    "    print('data augmentation configurado')\n",
    "    \n",
    "    #visualiza exemplos de augmentation\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    sample_img = x_train[0:1]\n",
    "    \n",
    "    axs[0, 0].imshow(sample_img[0].reshape(img_size, img_size), cmap='gray')\n",
    "    axs[0, 0].set_title('Original')\n",
    "    axs[0, 0].axis('off')\n",
    "    \n",
    "    for i, batch in enumerate(datagen.flow(sample_img, batch_size=1)):\n",
    "        if i >= 9:\n",
    "            break\n",
    "        row = (i + 1) // 5\n",
    "        col = (i + 1) % 5\n",
    "        axs[row, col].imshow(batch[0].reshape(img_size, img_size), cmap='gray')\n",
    "        axs[row, col].set_title(f'Aug {i+1}')\n",
    "        axs[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    datagen = None\n",
    "    print('data augmentation desativado')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133718f2",
   "metadata": {},
   "source": [
    "## 6. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7003c63",
   "metadata": {},
   "source": [
    "### 6.1 Construção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empilhamento de camadas para construir uma CNN\n",
    "\n",
    "act_function = 'relu'\n",
    "act_function_out = 'softmax'\n",
    "drop = 0.25\n",
    "initializer = tensorflow.keras.initializers.HeNormal()\n",
    "\n",
    "#entrada\n",
    "inputs = Input(shape=(img_size, img_size, 1), dtype='float32', name='input')\n",
    "\n",
    "#bloco convolucional 1\n",
    "conv1 = Conv2D(32, (3, 3), activation=act_function, padding='same', kernel_initializer=initializer)(inputs)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Conv2D(32, (3, 3), activation=act_function, padding='same', kernel_initializer=initializer)(conv1)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "drop1 = Dropout(drop)(pool1)\n",
    "\n",
    "#bloco convolucional 2\n",
    "conv2 = Conv2D(64, (3, 3), activation=act_function, padding='same', kernel_initializer=initializer)(drop1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Conv2D(64, (3, 3), activation=act_function, padding='same', kernel_initializer=initializer)(conv2)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "drop2 = Dropout(drop)(pool2)\n",
    "\n",
    "#bloco convolucional 3\n",
    "conv3 = Conv2D(128, (3, 3), activation=act_function, padding='same', kernel_initializer=initializer)(drop2)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Conv2D(128, (3, 3), activation=act_function, padding='same', kernel_initializer=initializer)(conv3)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "drop3 = Dropout(drop)(pool3)\n",
    "\n",
    "#camadas densas\n",
    "flat = Flatten()(drop3)\n",
    "dense1 = Dense(256, activation=act_function, kernel_initializer=initializer)(flat)\n",
    "dense1 = BatchNormalization()(dense1)\n",
    "drop4 = Dropout(0.5)(dense1)\n",
    "\n",
    "#saida\n",
    "outputs = Dense(num_classes, activation=act_function_out, name='output')(drop4)\n",
    "\n",
    "#geracao do modelo\n",
    "cnn_model = Model(inputs, outputs, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7da41",
   "metadata": {},
   "source": [
    "### 6.2 Inspecionando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8233d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(cnn_model, show_shapes=True, show_layer_names=True, rankdir=\"TB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326753f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train type:', type(x_train))\n",
    "print('y_train type:', type(y_train))\n",
    "print('x_train dtype:', x_train.dtype)\n",
    "print('y_train dtype:', y_train.dtype)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330eb4dc",
   "metadata": {},
   "source": [
    "### 6.3 Otimização do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_model:\n",
    "    \n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    \n",
    "    cnn_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    cp = ModelCheckpoint(\n",
    "        filepath='models/best_model.weights.h5',\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True\n",
    "    )\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', patience=80, restore_best_weights=True)\n",
    "    \n",
    "    if augmentation_exec and datagen is not None:\n",
    "        #treina com data augmentation\n",
    "        history = cnn_model.fit(\n",
    "            datagen.flow(x_train, y_train, batch_size=8),\n",
    "            validation_data=(x_val, y_val),\n",
    "            epochs=300,\n",
    "            verbose=1,\n",
    "            callbacks=[es, cp],\n",
    "            steps_per_epoch=len(x_train) // 8\n",
    "        )\n",
    "    else:\n",
    "        #treina sem data augmentation\n",
    "        history = cnn_model.fit(\n",
    "            x_train, y_train,\n",
    "            validation_data=(x_val, y_val),\n",
    "            epochs=300,\n",
    "            verbose=1,\n",
    "            callbacks=[es, cp],\n",
    "            batch_size=8,\n",
    "            shuffle=True\n",
    "        )\n",
    "    \n",
    "    np.save('models/history_model.npy', history.history)\n",
    "    cnn_model.load_weights('models/best_model.weights.h5')\n",
    "    cnn_model.save('models/' + model_name + '.h5')\n",
    "    \n",
    "else:\n",
    "    cnn_model = load_model('models/' + model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toca um som para avisar que terminou de executar\n",
    "pygame.mixer.init()\n",
    "arquivo_mp3 = 'support_files/mario_coin.mp3'\n",
    "\n",
    "if os.path.exists(arquivo_mp3):\n",
    "    pygame.mixer.music.load(arquivo_mp3)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        continue\n",
    "\n",
    "print('Sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a84456",
   "metadata": {},
   "source": [
    "### 6.4 Avaliação do modelo com curva de convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eae7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.load('models/history_model.npy', allow_pickle='TRUE').item()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('paper')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "#grafico de loss\n",
    "ax1.plot(history['loss'], label='treino')\n",
    "ax1.plot(history['val_loss'], label='validacao')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_xlabel('Época')\n",
    "ax1.set_title('Treino vs. Validação - Loss')\n",
    "ax1.legend()\n",
    "\n",
    "#grafico de accuracy\n",
    "ax2.plot(history['accuracy'], label='treino')\n",
    "ax2.plot(history['val_accuracy'], label='validacao')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_xlabel('Época')\n",
    "ax2.set_title('Treino vs. Validação - Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd665c38",
   "metadata": {},
   "source": [
    "## 7. Testando as previsões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac62984",
   "metadata": {},
   "source": [
    "### 7.1 Gerando as previsões com o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb547b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#realiza predicoes no conjunto de teste\n",
    "y_pred_prob = cnn_model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(f'predicoes realizadas: {len(y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744e5e94",
   "metadata": {},
   "source": [
    "### 7.2 Calculando a taxa de acerto com base na matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21143a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculando a matriz de confusao\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#calculando a taxa de acerto\n",
    "accuracy = np.trace(cm) / cm.sum()\n",
    "accuracy_percent = round(accuracy * 100, 2)\n",
    "print(f\"Taxa de Acerto: {accuracy_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.grid(False)\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predito', fontsize=12)\n",
    "plt.ylabel('Real', fontsize=12)\n",
    "plt.title('Matriz de Confusão')\n",
    "\n",
    "#adiciona rotulos dos eixos\n",
    "plt.xticks(range(num_classes), class_names)\n",
    "plt.yticks(range(num_classes), class_names)\n",
    "\n",
    "threshold = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        color = 'white' if cm[i, j] > threshold else 'black'\n",
    "        plt.text(j, i, str(cm[i, j]), ha='center', va='center', color=color, fontsize=14)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualiza_pred",
   "metadata": {},
   "source": [
    "### 7.3 Visualização das predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vis_pred_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualiza algumas predicoes\n",
    "fig, axs = plt.subplots(3, 5, figsize=(15, 10))\n",
    "\n",
    "indices = np.random.choice(len(x_test), 15, replace=False)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    \n",
    "    axs[row, col].imshow(x_test[idx].reshape(img_size, img_size), cmap='gray')\n",
    "    \n",
    "    pred_class = class_names[y_pred[idx]]\n",
    "    true_class = class_names[y_true[idx]]\n",
    "    confidence = y_pred_prob[idx][y_pred[idx]] * 100\n",
    "    \n",
    "    color = 'green' if y_pred[idx] == y_true[idx] else 'red'\n",
    "    axs[row, col].set_title(f'Pred: {pred_class} ({confidence:.1f}%)\\nReal: {true_class}', color=color)\n",
    "    axs[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "live_section",
   "metadata": {},
   "source": [
    "## 8. Predição ao vivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "live_intro",
   "metadata": {},
   "source": [
    "### 8.1 Função de predição ao vivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "live_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def live_prediction(model, class_names, img_size, box_size, confidence_threshold):\n",
    "    \"\"\"realiza predicao ao vivo usando a webcam\"\"\"\n",
    "    \n",
    "    #usa o backend AVFoundation no macOS para evitar crash\n",
    "    if sys.platform == 'darwin':\n",
    "        cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print('erro: nao foi possivel abrir a webcam')\n",
    "        return\n",
    "    \n",
    "    print('=== PREDICAO AO VIVO ===')\n",
    "    print('posicione-se dentro do quadrado')\n",
    "    print('pressione Q ou feche a janela para sair')\n",
    "    print('='*25)\n",
    "    \n",
    "    window_name = 'Predicao ao Vivo'\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_AUTOSIZE)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            #espelha a imagem\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            #define area de captura\n",
    "            h, w = frame.shape[:2]\n",
    "            cx, cy = w // 2, h // 2\n",
    "            \n",
    "            #extrai ROI\n",
    "            roi = frame[cy - box_size//2:cy + box_size//2, \n",
    "                        cx - box_size//2:cx + box_size//2]\n",
    "            \n",
    "            #preprocessa para o modelo\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "            roi_resized = cv2.resize(roi_gray, (img_size, img_size))\n",
    "            roi_normalized = roi_resized.astype('float32') / 255.0\n",
    "            roi_input = roi_normalized.reshape(1, img_size, img_size, 1)\n",
    "            \n",
    "            #realiza predicao\n",
    "            prediction = model.predict(roi_input, verbose=0)\n",
    "            pred_class = np.argmax(prediction)\n",
    "            confidence = prediction[0][pred_class]\n",
    "            \n",
    "            #determina o texto a exibir\n",
    "            if confidence >= confidence_threshold:\n",
    "                label = f'{class_names[pred_class]} ({confidence*100:.1f}%)'\n",
    "                color = (0, 255, 0)  #verde\n",
    "            else:\n",
    "                label = f'NADA ({confidence*100:.1f}%)'\n",
    "                color = (0, 0, 255)  #vermelho\n",
    "            \n",
    "            #desenha area de captura\n",
    "            cv2.rectangle(frame, (cx - box_size//2, cy - box_size//2), \n",
    "                        (cx + box_size//2, cy + box_size//2), color, 2)\n",
    "            \n",
    "            #adiciona texto com o resultado\n",
    "            cv2.putText(frame, label, (cx - box_size//2, cy - box_size//2 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            \n",
    "            #mostra barra de confianca\n",
    "            bar_width = int(box_size * confidence)\n",
    "            cv2.rectangle(frame, (cx - box_size//2, cy + box_size//2 + 10),\n",
    "                        (cx - box_size//2 + bar_width, cy + box_size//2 + 30), color, -1)\n",
    "            cv2.rectangle(frame, (cx - box_size//2, cy + box_size//2 + 10),\n",
    "                        (cx + box_size//2, cy + box_size//2 + 30), color, 2)\n",
    "            \n",
    "            #adiciona instrucoes\n",
    "            cv2.putText(frame, 'Pressione Q para sair', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow(window_name, frame)\n",
    "            \n",
    "            #verifica se usuario quer sair\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "            \n",
    "            #verifica se janela foi fechada\n",
    "            try:\n",
    "                if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                    break\n",
    "            except:\n",
    "                break\n",
    "    \n",
    "    finally:\n",
    "        #libera a camera e fecha a janela de forma segura\n",
    "        cap.release()\n",
    "        cv2.destroyWindow(window_name)\n",
    "        #processa eventos pendentes\n",
    "        for _ in range(10):\n",
    "            cv2.waitKey(1)\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    print('predicao ao vivo finalizada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "live_exec_section",
   "metadata": {},
   "source": [
    "### 8.2 Executar predição ao vivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "live_exec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega o modelo se necessario\n",
    "if 'cnn_model' not in dir() or cnn_model is None:\n",
    "    cnn_model = load_model('models/' + model_name + '.h5')\n",
    "    print('modelo carregado')\n",
    "\n",
    "#inicia predicao ao vivo\n",
    "live_prediction(cnn_model, class_names, img_size, box_size, confidence_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redesneurais",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
